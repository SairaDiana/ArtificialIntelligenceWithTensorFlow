library(e1071)
confusionatrix(prediccion, data2$Species)
MC <- confusionMatrix(prediccion, data2$Species)
MC <- confusionMatrix(data2$MEDV, result))
(MC <- confusionMatrix(data2$MEDV, result))
g1<- ROCR(data1$MEDV~ as.numeric(result))
install.packages("ROCR")
datos <- iris
datos
n<-sample (1:150, 30)
n
entrenamiento <- datos[-n]
entrenamiento
test<-datos[n,]
View(test)
modelo <- naive_bayes(Species ~ . , data=test, laplace = 1)
modelo <- naiveBayes(Species ~ . , data=test, laplace = 1)
predict(modelo, test)
predicciones1 <- predict(modelo, test)
predicciones1
tarjeta_predicciones<-cbind(test, predicciones1)
tarjeta_predicciones
comparacion
ftable(comparacion, row.vars = "predicted", col.vars = "MEDV")
ftable(comparacion, row.vars = predicted, col.vars = MEDV)
ftable(tarjeta_predicciones, row.vars = "predicciones1", col.vars = "Species")
table(comparacion, row.vars = predicted, col.vars = MEDV)
table(comparacion, row.vars = "predicted", col.vars = "MEDV")
comparacion
Hola<-table(comparacion, row.vars = "predicted", col.vars = "MEDV")
predicciones1
prediccion
result
Hola<-table(comparacion, row.vars = "result", col.vars = "MEDV")
CM<-confusionMatrix(result, data2$MEDV)
CM<-confusionMatrix(result, data2$MEDV)
CM<-confusionMatrix(result, data2$MEDV)
data2 <- read.csv("DIPLOMADO/MODULO IV/Proyecto-ModuloIV-MineriaDeDatos/DataSets/testing.csv")
#Las siguientes lineas convierten a la variable objetivo en valores booleanos
data2$s<-c(data2$MEDV=="s")
data2$n<-c(data2$MEDV=="n")
#Con la librerï¿½a neuralnet se contruye la red neuronal con el algoritmo de retropropagaciï¿½n
modelo=neuralnet(s + n ~ age	+ sex +	cp + trestbps + chol + restecg + thalach +	exang	+ oldpeak	+ slope	+ ca	+ thal,
data2, hidden = 4,
lifesign = "full",
algorithm = "rprop+")
#Ahora, se va a construir la grï¿½fica de la red neuronal
plot(modelo, rep = "best")
plot(modelo, rep = "best", intercept = FALSE)
#Ahora se recorre la tabla completa para hacer calculo de as predicciones
prediccion <- compute(modelo, data2[1:12])
prediccion
which.max(prediccion$net.result[1,])
result<-0
for (i in 1:73) {result[i] <- which.max(prediccion$net.result[i,])}
for (i in 1:73) {if (result[i]==1) {result[i] = "s"}}
for (i in 1:73) {if (result[i]==2) {result[i] = "n"}}
#Se hace una comparaciï¿½n de las clases reales con las predicciones
comparacion<-data2
comparacion$predicted<-result
comparacion
result
confusionMatrix(comparacion$predicted, comparacion$MEDV)
confusionMatrix(table(comparacion$predicted, comparacion$MEDV))
g1<- ROCR(comparacion$MEDV ~ as.numeric(comparacion$predicted))
library(ROCR)
g1<- ROCR(comparacion$MEDV ~ as.numeric(comparacion$predicted))
install.packages("neuralnet")
install.packages("neuralnet")
install.packages("neuralnet")
install.packages("neuralnet")
install.packages("neuralnet")
install.packages("neuralnet")
install.packages("neuralnet")
install.packages("neuralnet")
install.packages("neuralnet")
install.packages("neuralnet")
library(devtools)
detach("package:devtools", unload = TRUE)
library(e1071)
library(ggplot2)
library(neuralnet)
library(ROCR)
g1<- ROCR(comparacion$MEDV ~ as.numeric(comparacion$predicted))
remove.packages("ROCR", lib="~/R/win-library/3.6")
install.packages("ROCR")
library(ROCR)
g1<- ROCR(comparacion$MEDV ~ as.numeric(comparacion$predicted))
g1<- ROCR::(comparacion$MEDV ~ as.numeric(comparacion$predicted))
ROCR::plot(comparacion$MEDV ~ as.numeric(comparacion$predicted)
ROCR::plot(comparacion$MEDV ~ as.numeric(comparacion$predicted))
g1<- ROCR::(comparacion$MEDV ~ as.numeric(comparacion$predicted))
library(ROC632)
g1<- ROC(comparacion$MEDV ~ as.numeric(comparacion$predicted))
g1<- ROCR(comparacion$MEDV ~ as.numeric(comparacion$predicted))
library(neuralnet)
ftable(comparacion, row.vars = comparacion$predicted, col.vars = comparacion$MEDV)
table(comparacion, row.vars = comparacion$predicted, col.vars = comparacion$MEDV)
ftable(comparacion, row.vars = comparacion$predicted, col.vars = comparacion$MEDV)
result
ftable(comparacion, row.vars = comparacion$predicted, col.vars = comparacion$MEDV)
confusionMatrix(table(comparacion$predicted, comparacion$MEDV))
confusionMatrix(table(comparacion$predicted, comparacion$MEDV))
library(caret)
library(e1071)
MC<-confusio(table(comparacion$predicted, comparacion$MEDV))
MC<-confusionMatrix(table(comparacion$predicted, comparacion$MEDV))
MC
g1<- ROCR(comparacion$MEDV ~ as.numeric(comparacion$predicted))
g1<- ROC(comparacion$MEDV ~ as.numeric(comparacion$predicted))
prediccion <- table(comparacion$predicted, comparacion$MEDV)
prediccion
prediccion <- table(comparacion$predicted, comparacion$MEDV)
prediccion
prediccion <-(comparacion$predicted, comparacion$MEDV)
prediccion <- (comparacion$predicted$MEDV)
prediccion2 <- (comparacion$, predicted$MEDV)
prediccion2
prediccion2 <- (comparacion$predicted, predicted$MEDV)
prediccion2 <- comparacion$predicted, predicted$MEDV
#Se hace una comparaciï¿½n de las clases reales con las predicciones
comparacion<-data2
comparacion$predicted<-result
comparacion
result
MC<-confusionMatrix(table(comparacion$predicted, comparacion$MEDV))
MC
prediccion2 <- comparacion$predicted, predicted$MEDV
prediccion2 <- comparacion$predicted, comparacion$MEDV
prediccion2 <- comparacion$predicted
prediccion2
comparacion
View(comparacion)
prediccion2 <- c(13, 16)
prediccion2
prediccion2
prediccion2 <- [,c(13, 16)]
prediccion2[,c(13, 16)]
comparacion[,c(13, 16)]
prediccion2 <- comparacion[,c(13, 16)]
prediccion2
plot(prediccion2)
perf1 <- performance(prediccion2, "tpr", "fpr")
g1<- ROC(prediccion2$MEDV ~ as.numeric(prediccion2$predicted))
g1<- ROCR(prediccion2$MEDV ~ as.numeric(prediccion2$predicted))
g1<- ROCR(prediccion2$MEDV ~ as.numeric(result))
g1<- ROC(prediccion2$MEDV ~ as.numeric(result))
MC<-confusionMatrix(table(comparacion$predicted, comparacion$MEDV))
data2 <- read.csv("DIPLOMADO/MODULO IV/Proyecto-ModuloIV-MineriaDeDatos/DataSets/testing.csv")
#Las siguientes lineas convierten a la variable objetivo en valores booleanos
data2$s<-c(data2$MEDV=="s")
data2$n<-c(data2$MEDV=="n")
#Con la librerï¿½a neuralnet se contruye la red neuronal con el algoritmo de retropropagaciï¿½n
modelo=neuralnet(s + n ~ age	+ sex +	cp + trestbps + chol + restecg + thalach +	exang	+ oldpeak	+ slope	+ ca	+ thal,
data2, hidden = 4,
lifesign = "full",
algorithm = "rprop+")
#Ahora, se va a construir la grï¿½fica de la red neuronal
plot(modelo, rep = "best")
plot(modelo, rep = "best", intercept = FALSE)
#Ahora se recorre la tabla completa para hacer calculo de as predicciones
prediccion <- compute(modelo, data2[1:12])
prediccion
which.max(prediccion$net.result[1,])
result<-0
for (i in 1:73) {result[i] <- which.max(prediccion$net.result[i,])}
for (i in 1:73) {if (result[i]==1) {result[i] = "s"}}
for (i in 1:73) {if (result[i]==2) {result[i] = "n"}}
#Se hace una comparaciï¿½n de las clases reales con las predicciones
comparacion<-data2
comparacion$predicted<-result
comparacion
result
MC<-confusionMatrix(table(comparacion$predicted, comparacion$MEDV))
MC
prediccion2 <- comparacion[,c(13, 16)]
g1<- ROC(prediccion2$MEDV ~ as.numeric(result))
library(pROC)
g1<- ROC(prediccion2$MEDV ~ as.numeric(prediccion2$predicted))
MC<-confusionMatrix(table(comparacion$predicted, comparacion$MEDV))
MC
prediccion2 <- comparacion[,c(13, 16)]
g1<- ROC(prediccion2$MEDV ~ as.numeric(prediccion2$predicted))
g1<- roc(prediccion2$MEDV ~ as.numeric(prediccion2$predicted))
data2 <- read.csv("DIPLOMADO/MODULO IV/Proyecto-ModuloIV-MineriaDeDatos/DataSets/testing.csv")
#Las siguientes lineas convierten a la variable objetivo en valores booleanos
data2$s<-c(data2$MEDV=="s")
data2$n<-c(data2$MEDV=="n")
#Con la librerï¿½a neuralnet se contruye la red neuronal con el algoritmo de retropropagaciï¿½n
modelo=neuralnet(s + n ~ age	+ sex +	cp + trestbps + chol + restecg + thalach +	exang	+ oldpeak	+ slope	+ ca	+ thal,
data2, hidden = 4,
lifesign = "full",
algorithm = "rprop+")
#Ahora, se va a construir la grï¿½fica de la red neuronal
plot(modelo, rep = "best")
plot(modelo, rep = "best", intercept = FALSE)
#Ahora se recorre la tabla completa para hacer calculo de as predicciones
prediccion <- compute(modelo, data2[1:12])
prediccion
which.max(prediccion$net.result[1,])
result<-0
for (i in 1:73) {result[i] <- which.max(prediccion$net.result[i,])}
for (i in 1:73) {if (result[i]==1) {result[i] = "s"}}
for (i in 1:73) {if (result[i]==2) {result[i] = "n"}}
#Se hace una comparaciï¿½n de las clases reales con las predicciones
comparacion<-data2
comparacion$predicted<-result
comparacion
result
MC<-confusionMatrix(table(comparacion$predicted, comparacion$MEDV))
MC<-confusionMatrix(table(comparacion$predicted, comparacion$MEDV))
data2 <- read.csv("DIPLOMADO/MODULO IV/Proyecto-ModuloIV-MineriaDeDatos/DataSets/testing.csv")
#Las siguientes lineas convierten a la variable objetivo en valores booleanos
data2$s<-c(data2$MEDV=="s")
data2$n<-c(data2$MEDV=="n")
#Con la librerï¿½a neuralnet se contruye la red neuronal con el algoritmo de retropropagaciï¿½n
modelo=neuralnet(s + n ~ age	+ sex +	cp + trestbps + chol + restecg + thalach +	exang	+ oldpeak	+ slope	+ ca	+ thal,
data2, hidden = 4,
lifesign = "full",
algorithm = "rprop+")
data1 <- read.csv("DIPLOMADO/MODULO IV/Proyecto-ModuloIV-MineriaDeDatos/DataSets/trainig.csv")
#Las siguientes lineas convierten a la variable objetivo en valores booleanos
data1$s<-c(data1$MEDV=="s")
data1$n<-c(data1$MEDV=="n")
#Con la librerï¿½a neuralnet se contruye la red neuronal con el algoritmo de retropropagaciï¿½n
modelo=neuralnet(s + n ~ age	+ sex +	cp + trestbps + chol + restecg + thalach +	exang	+ oldpeak	+ slope	+ ca	+ thal,
data1, hidden = 4,
lifesign = "full",
algorithm = "rprop+")
library(neuralnet)
#Con la librerï¿½a neuralnet se contruye la red neuronal con el algoritmo de retropropagaciï¿½n
modelo=neuralnet(s + n ~ age	+ sex +	cp + trestbps + chol + restecg + thalach +	exang	+ oldpeak	+ slope	+ ca	+ thal,
data1, hidden = 4,
lifesign = "full",
algorithm = "rprop+")
#Ahora, se va a construir la grï¿½fica de la red neuronal
plot(modelo, rep = "best")
plot(modelo, rep = "best", intercept = FALSE)
#Ahora se recorre la tabla completa para hacer calculo de as predicciones
prediccion <- compute(modelo, data1[1:12])
prediccion
which.max(prediccion$net.result[1,])
result<-0
for (i in 1:229) {result[i] <- which.max(prediccion$net.result[i,])}
for (i in 1:229) {if (result[i]==1) {result[i] = "s"}}
for (i in 1:229) {if (result[i]==2) {result[i] = "n"}}
#Se hace una comparaciï¿½n de las clases reales con las predicciones
comparacion<-data1
comparacion$predicted<-result
comparacion
#Por ï¿½ltimo se obtiene la matriz de confusion, en la cual los valores de la diagonal son
#los mï¿½s importantes, ya que con ellos se pueden calcular la precisiï¿½n del modelo
(MC <- table(data1$MEDV, result))
data2 <- read.csv("PrediccionTesting.csv")
data2 <- read.csv("DIPLOMADO/MODULO IV/Proyecto-ModuloIV-MineriaDeDatos/DataSets/testing.csv")
#Las siguientes lineas convierten a la variable objetivo en valores booleanos
data2$s<-c(data2$MEDV=="s")
data2$n<-c(data2$MEDV=="n")
#Con la librerï¿½a neuralnet se contruye la red neuronal con el algoritmo de retropropagaciï¿½n
modelo=neuralnet(s + n ~ age	+ sex +	cp + trestbps + chol + restecg + thalach +	exang	+ oldpeak	+ slope	+ ca	+ thal,
data2, hidden = 4,
lifesign = "full",
algorithm = "rprop+")
#Ahora, se va a construir la grï¿½fica de la red neuronal
plot(modelo, rep = "best")
plot(modelo, rep = "best", intercept = FALSE)
#Ahora se recorre la tabla completa para hacer calculo de as predicciones
prediccion <- compute(modelo, data2[1:12])
prediccion
which.max(prediccion$net.result[1,])
result<-0
for (i in 1:73) {result[i] <- which.max(prediccion$net.result[i,])}
for (i in 1:73) {if (result[i]==1) {result[i] = "s"}}
for (i in 1:73) {if (result[i]==2) {result[i] = "n"}}
#Se hace una comparaciï¿½n de las clases reales con las predicciones
comparacion<-data2
comparacion$predicted<-result
comparacion
result
MC<-confusionMatrix(table(comparacion$predicted, comparacion$MEDV))
MC
data2 <- read.csv("DIPLOMADO/MODULO IV/Proyecto-ModuloIV-MineriaDeDatos/DataSets/testing.csv")
#Las siguientes lineas convierten a la variable objetivo en valores booleanos
data2$s<-c(data2$MEDV=="s")
data2$n<-c(data2$MEDV=="n")
#Con la librerï¿½a neuralnet se contruye la red neuronal con el algoritmo de retropropagaciï¿½n
modelo=neuralnet(s + n ~ age	+ sex +	cp + trestbps + chol + restecg + thalach +	exang	+ oldpeak	+ slope	+ ca	+ thal,
data2, hidden = 4,
lifesign = "full",
algorithm = "rprop+")
#Ahora, se va a construir la grï¿½fica de la red neuronal
plot(modelo, rep = "best")
plot(modelo, rep = "best", intercept = FALSE)
#Ahora se recorre la tabla completa para hacer calculo de as predicciones
prediccion <- compute(modelo, data2[1:12])
prediccion
which.max(prediccion$net.result[1,])
result<-0
for (i in 1:73) {result[i] <- which.max(prediccion$net.result[i,])}
for (i in 1:73) {if (result[i]==1) {result[i] = "s"}}
for (i in 1:73) {if (result[i]==2) {result[i] = "n"}}
#Se hace una comparaciï¿½n de las clases reales con las predicciones
comparacion<-data2
comparacion$predicted<-result
comparacion
result
MC<-confusionMatrix(table(comparacion$predicted, comparacion$MEDV))
MC
prediccion2 <- comparacion[,c(13, 16)]
g1<- roc(prediccion2$MEDV ~ as.numeric(prediccion2$predicted))
data2 <- read.csv("DIPLOMADO/MODULO IV/Proyecto-ModuloIV-MineriaDeDatos/DataSets/testing.csv")
#Las siguientes lineas convierten a la variable objetivo en valores booleanos
data2$s<-c(data2$MEDV=="s")
data2$n<-c(data2$MEDV=="n")
#Con la librerï¿½a neuralnet se contruye la red neuronal con el algoritmo de retropropagaciï¿½n
modelo=neuralnet(s + n ~ age	+ sex +	cp + trestbps + chol + restecg + thalach +	exang	+ oldpeak	+ slope	+ ca	+ thal,
data2, hidden = 4,
lifesign = "full",
algorithm = "rprop+")
#Ahora, se va a construir la grï¿½fica de la red neuronal
plot(modelo, rep = "best")
plot(modelo, rep = "best", intercept = FALSE)
#Ahora se recorre la tabla completa para hacer calculo de as predicciones
prediccion <- compute(modelo, data2[1:12])
prediccion
which.max(prediccion$net.result[1,])
result<-0
for (i in 1:73) {result[i] <- which.max(prediccion$net.result[i,])}
for (i in 1:73) {if (result[i]==1) {result[i] = "s"}}
for (i in 1:73) {if (result[i]==2) {result[i] = "n"}}
#Se hace una comparaciï¿½n de las clases reales con las predicciones
comparacion<-data2
comparacion$predicted<-result
comparacion
result
(MC <- table(data1$MEDV, result))
(MC <- table(data2$MEDV, result))
data1 <- read.csv("DIPLOMADO/MODULO IV/Proyecto-ModuloIV-MineriaDeDatos/DataSets/trainig.csv")
#Las siguientes lineas convierten a la variable objetivo en valores booleanos
data1$s<-c(data1$MEDV=="s")
data1$n<-c(data1$MEDV=="n")
#Con la librerï¿½a neuralnet se contruye la red neuronal con el algoritmo de retropropagaciï¿½n
modelo=neuralnet(s + n ~ age	+ sex +	cp + trestbps + chol + restecg + thalach +	exang	+ oldpeak	+ slope	+ ca	+ thal,
data1, hidden = 4,
lifesign = "full",
algorithm = "rprop+")
#Ahora, se va a construir la grï¿½fica de la red neuronal
plot(modelo, rep = "best")
plot(modelo, rep = "best", intercept = FALSE)
#Ahora se recorre la tabla completa para hacer calculo de as predicciones
prediccion <- compute(modelo, data1[1:12])
prediccion
which.max(prediccion$net.result[1,])
result<-0
for (i in 1:229) {result[i] <- which.max(prediccion$net.result[i,])}
for (i in 1:229) {if (result[i]==1) {result[i] = "s"}}
for (i in 1:229) {if (result[i]==2) {result[i] = "n"}}
#Se hace una comparaciï¿½n de las clases reales con las predicciones
comparacion<-data1
comparacion$predicted<-result
comparacion
#Por ï¿½ltimo se obtiene la matriz de confusion, en la cual los valores de la diagonal son
#los mï¿½s importantes, ya que con ellos se pueden calcular la precisiï¿½n del modelo
(MC <- table(data1$MEDV, result))
Proyecto
data2 <- read.csv("DIPLOMADO/MODULO IV/Proyecto-ModuloIV-MineriaDeDatos/DataSets/testing.csv")
#Las siguientes lineas convierten a la variable objetivo en valores booleanos
data2$s<-c(data2$MEDV=="s")
data2$n<-c(data2$MEDV=="n")
#Con la librerï¿½a neuralnet se contruye la red neuronal con el algoritmo de retropropagaciï¿½n
modelo=neuralnet(s + n ~ age	+ sex +	cp + trestbps + chol + restecg + thalach +	exang	+ oldpeak	+ slope	+ ca	+ thal,
data2, hidden = 4,
lifesign = "full",
algorithm = "rprop+")
#Ahora, se va a construir la grï¿½fica de la red neuronal
plot(modelo, rep = "best")
plot(modelo, rep = "best", intercept = FALSE)
#Ahora se recorre la tabla completa para hacer calculo de as predicciones
prediccion <- compute(modelo, data2[1:12])
prediccion
which.max(prediccion$net.result[1,])
result<-0
for (i in 1:73) {result[i] <- which.max(prediccion$net.result[i,])}
for (i in 1:73) {if (result[i]==1) {result[i] = "s"}}
for (i in 1:73) {if (result[i]==2) {result[i] = "n"}}
#Se hace una comparaciï¿½n de las clases reales con las predicciones
comparacion<-data2
comparacion$predicted<-result
comparacion
result
(MC <- table(data2$MEDV, result))
#Exportar la tabla con la predicciones para sacar tablas de contigencia
setwd("C:/Users/saira/Documents/DIPLOMADO/MODULO IV/Proyecto-ModuloIV-MineriaDeDatos/DataSets/")
write.csv(comparacion, file="prediccion-testing.csv")
data1 <- read.csv("DIPLOMADO/MODULO IV/Proyecto-ModuloIV-MineriaDeDatos/DataSets/trainig.csv")
data1 <- read.csv("trainig.csv")
#Las siguientes lineas convierten a la variable objetivo en valores booleanos
data1$s<-c(data1$MEDV=="s")
data1$n<-c(data1$MEDV=="n")
#Con la librerï¿½a neuralnet se contruye la red neuronal con el algoritmo de retropropagaciï¿½n
modelo=neuralnet(s + n ~ age	+ sex +	cp + trestbps + chol + restecg + thalach +	exang	+ oldpeak	+ slope	+ ca	+ thal,
data1, hidden = 4,
lifesign = "full",
algorithm = "rprop+")
#Ahora, se va a construir la grï¿½fica de la red neuronal
plot(modelo, rep = "best")
plot(modelo, rep = "best", intercept = FALSE)
#Ahora se recorre la tabla completa para hacer calculo de as predicciones
prediccion <- compute(modelo, data1[1:12])
prediccion
which.max(prediccion$net.result[1,])
result<-0
for (i in 1:229) {result[i] <- which.max(prediccion$net.result[i,])}
for (i in 1:229) {if (result[i]==1) {result[i] = "s"}}
for (i in 1:229) {if (result[i]==2) {result[i] = "n"}}
#Se hace una comparaciï¿½n de las clases reales con las predicciones
comparacion<-data1
comparacion$predicted<-result
comparacion
#Por ï¿½ltimo se obtiene la matriz de confusion, en la cual los valores de la diagonal son
#los mï¿½s importantes, ya que con ellos se pueden calcular la precisiï¿½n del modelo
(MC <- table(data1$MEDV, result))
data1 <- read.csv("trainig.csv")
#Las siguientes lineas convierten a la variable objetivo en valores booleanos
data1$s<-c(data1$MEDV=="s")
data1$n<-c(data1$MEDV=="n")
#Con la librerï¿½a neuralnet se contruye la red neuronal con el algoritmo de retropropagaciï¿½n
modelo=neuralnet(s + n ~ age	+ sex +	cp + trestbps + chol + restecg + thalach +	exang	+ oldpeak	+ slope	+ ca	+ thal,
data1, hidden = 4,
lifesign = "full",
algorithm = "rprop+")
#Ahora, se va a construir la grï¿½fica de la red neuronal
plot(modelo, rep = "best")
plot(modelo, rep = "best", intercept = FALSE)
#Ahora se recorre la tabla completa para hacer calculo de as predicciones
prediccion <- compute(modelo, data1[1:12])
prediccion
which.max(prediccion$net.result[1,])
result<-0
for (i in 1:229) {result[i] <- which.max(prediccion$net.result[i,])}
for (i in 1:229) {if (result[i]==1) {result[i] = "s"}}
for (i in 1:229) {if (result[i]==2) {result[i] = "n"}}
#Se hace una comparaciï¿½n de las clases reales con las predicciones
comparacion<-data1
comparacion$predicted<-result
comparacion
#Por ï¿½ltimo se obtiene la matriz de confusion, en la cual los valores de la diagonal son
#los mï¿½s importantes, ya que con ellos se pueden calcular la precisiï¿½n del modelo
(MC <- table(data1$MEDV, result))
#Exportar la tabla con la predicciones para sacar tablas de contigencia
setwd("C:/Users/saira/Documents/DIPLOMADO/MODULO IV/Proyecto-ModuloIV-MineriaDeDatos/DataSets/")
write.csv(comparacion, file="prediccion-trainig.csv")
#Exportar la tabla con la predicciones para sacar tablas de contigencia
setwd("C:/Users/saira/Documents/DIPLOMADO/MODULO IV/Proyecto-ModuloIV-MineriaDeDatos/DataSets/")
write.csv(comparacion, file="prediccion-trainig.csv")
(MC <- table(data2$MEDV, result))
#Exportar la tabla con la predicciones para sacar tablas de contigencia
setwd("C:/Users/saira/Documents/DIPLOMADO/MODULO IV/Proyecto-ModuloIV-MineriaDeDatos/DataSets/")
write.csv(comparacion, file="prediccion-testing.csv")
data2 <- read.csv("DIPLOMADO/MODULO IV/Proyecto-ModuloIV-MineriaDeDatos/DataSets/testing.csv")
data2 <- read.csv("testing.csv")
#Las siguientes lineas convierten a la variable objetivo en valores booleanos
data2$s<-c(data2$MEDV=="s")
data2$n<-c(data2$MEDV=="n")
#Con la librerï¿½a neuralnet se contruye la red neuronal con el algoritmo de retropropagaciï¿½n
modelo=neuralnet(s + n ~ age	+ sex +	cp + trestbps + chol + restecg + thalach +	exang	+ oldpeak	+ slope	+ ca	+ thal,
data2, hidden = 4,
lifesign = "full",
algorithm = "rprop+")
#Ahora, se va a construir la grï¿½fica de la red neuronal
plot(modelo, rep = "best")
plot(modelo, rep = "best", intercept = FALSE)
#Ahora se recorre la tabla completa para hacer calculo de as predicciones
prediccion <- compute(modelo, data2[1:12])
prediccion
which.max(prediccion$net.result[1,])
result<-0
for (i in 1:73) {result[i] <- which.max(prediccion$net.result[i,])}
for (i in 1:73) {if (result[i]==1) {result[i] = "s"}}
for (i in 1:73) {if (result[i]==2) {result[i] = "n"}}
#Se hace una comparaciï¿½n de las clases reales con las predicciones
comparacion<-data2
comparacion$predicted<-result
comparacion
result
(MC <- table(data2$MEDV, result))
data2 <- read.csv("testing.csv")
#Las siguientes lineas convierten a la variable objetivo en valores booleanos
data2$s<-c(data2$MEDV=="s")
data2$n<-c(data2$MEDV=="n")
#Con la librerï¿½a neuralnet se contruye la red neuronal con el algoritmo de retropropagaciï¿½n
modelo=neuralnet(s + n ~ age	+ sex +	cp + trestbps + chol + restecg + thalach +	exang	+ oldpeak	+ slope	+ ca	+ thal,
data2, hidden = 4,
lifesign = "full",
algorithm = "rprop+")
#Ahora, se va a construir la grï¿½fica de la red neuronal
plot(modelo, rep = "best")
plot(modelo, rep = "best", intercept = FALSE)
#Ahora se recorre la tabla completa para hacer calculo de as predicciones
prediccion <- compute(modelo, data2[1:12])
prediccion
which.max(prediccion$net.result[1,])
result<-0
for (i in 1:73) {result[i] <- which.max(prediccion$net.result[i,])}
for (i in 1:73) {if (result[i]==1) {result[i] = "s"}}
for (i in 1:73) {if (result[i]==2) {result[i] = "n"}}
#Se hace una comparaciï¿½n de las clases reales con las predicciones
comparacion<-data2
comparacion$predicted<-result
comparacion
result
(MC <- table(data2$MEDV, result))
